# ğŸ” LLM eBPF Tracer

**Trace and analyze Large Language Model (LLM) inference workloads (e.g., PyTorch + CUDA) at the Linux kernel level using eBPF.**

This project enables system-level observability for modern AI inference pipelines â€” revealing what happens when LLMs interact with memory, CPUs, GPUs, and the filesystem under the hood.

---

## ğŸ§  Why This Project?

LLMs like LLaMA, Mistral, and GPT-variants require optimized infrastructure. While most focus on model design or training, inference performance depends heavily on OS-level behaviors like:

- File I/O for model weights (multi-GB mmap)
- CPU-GPU data paths and device access
- Thread pinning, scheduling, and NUMA locality
- Page locking (mlock) and memory pressure

Traditional profilers miss this. **eBPF (extended Berkeley Packet Filter)** allows us to trace these interactions with zero modification to the model code or OS kernel.

---

## ğŸ“¦ Features

- âœ… Trace `mmap`, `mlock`, `openat` during model loading
- âœ… Visualize `sched_switch` to track inference thread behavior
- âœ… Monitor access to `/dev/nvidia*` (GPU devices)
- âœ… Support for PyTorch, TensorRT, and Hugging Face model servers
- âœ… Plug-and-play tracing using `bpftrace` and `bcc`
- ğŸ§ª Optional integration with Prometheus and Grafana dashboards

---

## ğŸ–¼ï¸ Architecture Overview

![LLM Tracing Architecture](./docs/llm-ebpf-tracer.png)

---

## âš™ï¸ Example Tracing Scripts

### ğŸ§© Track `mmap` Usage (Model Weights Loading)

```bash
bpftrace -e 'tracepoint:syscalls:sys_enter_mmap { @[comm] = count(); }'
```

### ğŸ”’ Monitor Memory Locking (PyTorchâ€™s `mlock` Calls)

```bash
bpftrace -e 'tracepoint:syscalls:sys_enter_mlock { @[comm] = count(); }'
```

### ğŸ” Visualize Scheduler Switches (CPU Thread Behavior)

```bash
bpftrace -e 'tracepoint:sched:sched_switch { @[prev_comm, next_comm] = count(); }'
```

### ğŸ® Watch GPU Access (Device File Usage)

```bash
bpftrace -e 'tracepoint:syscalls:sys_enter_openat /str(args->filename) =~ "/dev/nvidia.*/" / { @[comm] = count(); }'
```
---

## ğŸ“Š Planned Dashboard (Work in Progress)

- ğŸ”¹ Model load phase duration
- ğŸ”¹ `mmap` vs `mlock` event frequency
- ğŸ”¹ CPU usage per inference worker
- ğŸ”¹ NUMA locality and scheduling efficiency
- ğŸ”¹ Live latency trends per token

---

## ğŸ“ Repo Layout

```bash
.
â”œâ”€â”€ scripts/               # bpftrace tracing scripts
â”‚   â”œâ”€â”€ mmap.bt
â”‚   â”œâ”€â”€ mlock.bt
â”‚   â”œâ”€â”€ sched.bt
â”‚   â””â”€â”€ gpu_access.bt
â”œâ”€â”€ dashboards/            # (WIP) Grafana dashboards for LLM workload visibility
â”œâ”€â”€ benchmark/             # Scripts to benchmark LLM inference performance
â”œâ”€â”€ README.md              # This file
â””â”€â”€ LICENSE
```
---
## ğŸ’¡ Use Cases

- Debug slow inference cold starts due to poor I/O or mmap
- Optimize thread pinning and scheduling latency
- Monitor GPU usage contention in shared environments
- Profile PyTorch and TensorRT workloads at system level
- Tune NUMA policies for large model inference

---

## ğŸš€ Getting Started

### âœ… Prerequisites

- Linux kernel â‰¥ 5.8
- `clang`, `llc`, and `bpftool` installed
- Go â‰¥ 1.20
- Root/sudo access (required to load eBPF programs)

```bash
sudo apt update
sudo apt install \
  linux-headers-$(uname -r) \
  build-essential \
  clang llvm libelf-dev libbpf-dev
```
---

### ğŸ”§ Build Instructions

#### 1. **Clone the Repo**

```bash
git clone https://github.com/ravikumar1907/llm-ebpf-tracer
cd llm-ebpf-tracer
```

#### 2. **Build the eBPF C Programs**

```bash
make bpf
```

This should generate `.o` object files from the `bpf/*.bpf.c` sources.

---

#### 3. **Run the Go Tracer**

```bash
sudo go run ./cmd/main.go
```

You should see log output like:

```
Listening for mmap events... Press Ctrl+C to stop.
Received mmap trace event, raw bytes: [120 156 ...]
```

---

### ğŸ§ª Simulate an mmap Syscall

Open another terminal and run:

```bash
python3 -c "import torch; torch.zeros((10000, 10000)).cuda()"
```

This will trigger `mmap` and possibly `mlock` + `/dev/nvidia*` accesses.

You should see trace output from the eBPF tracer as those syscalls happen.

---

### ğŸ“ˆ View Metrics (Optional)

If you enabled the Prometheus exporter:

```bash
curl http://localhost:2112/metrics
```

---

## ğŸ™‹â€â™‚ï¸ Contributions Welcome

We're looking for collaborators who are into:

- PyTorch, HuggingFace, or vLLM internals
- Kernel memory and NUMA optimization
- eBPF, tracing, and observability pipelines

Open an issue, drop a PR, or just DM me on LinkedIn!

---

## ğŸ“¬ Author

**Ravikumar Vallabhu**  
Linux Kernel + AI Infra Enthusiast  
[LinkedIn â†’](https://www.linkedin.com/in/ravikumar-vallabhu-62b7518/)  
[GitHub â†’](https://github.com/ravikumar1907/llm-ebpf-tracer)

---

## ğŸ“˜ License

MIT License â€” Free to use, modify, and share.

---